{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAYANTHNITW/NLP/blob/main/MultichannelCNNArchitecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-MknRbkBBeF"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense,Embedding,Dropout,LSTM,GRU,Flatten,Conv1D,Input,GlobalMaxPool1D,Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XtK7FGwJifln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"Dataset-Multitask1.csv\")\n",
        "df_train.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WzHzBs8bikkk",
        "outputId": "1d77a037-00ec-4b55-ac6d-9159d1ba5fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                               Text  Sarcasm  \\\n",
              "7284        1150  @AngelLamuno @lunarossa Relax mate, we have a ...        0   \n",
              "7285        1151  This doesn't mean that you relax on COVID 19, ...        0   \n",
              "7286        1152  Melbourne to relax third lockdown as no new CO...        0   \n",
              "7287        1153  JUST IN: Mayors vote 9-8 to put Metro Manila u...        0   \n",
              "7288        1154  You can return to your social apps and news, b...        1   \n",
              "\n",
              "      Stress  \n",
              "7284       0  \n",
              "7285       0  \n",
              "7286       0  \n",
              "7287       0  \n",
              "7288       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e349852-0152-46d7-987a-75ae70fba438\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Stress</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7284</th>\n",
              "      <td>1150</td>\n",
              "      <td>@AngelLamuno @lunarossa Relax mate, we have a ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7285</th>\n",
              "      <td>1151</td>\n",
              "      <td>This doesn't mean that you relax on COVID 19, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7286</th>\n",
              "      <td>1152</td>\n",
              "      <td>Melbourne to relax third lockdown as no new CO...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7287</th>\n",
              "      <td>1153</td>\n",
              "      <td>JUST IN: Mayors vote 9-8 to put Metro Manila u...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7288</th>\n",
              "      <td>1154</td>\n",
              "      <td>You can return to your social apps and news, b...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e349852-0152-46d7-987a-75ae70fba438')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e349852-0152-46d7-987a-75ae70fba438 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e349852-0152-46d7-987a-75ae70fba438');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3f8d9ba5-3d82-44b1-a20d-6fd5dde4cfd0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f8d9ba5-3d82-44b1-a20d-6fd5dde4cfd0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3f8d9ba5-3d82-44b1-a20d-6fd5dde4cfd0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"Dataset-Multitask1.csv\")\n",
        "df1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8mg-ylFIH5E",
        "outputId": "3ad64313-0748-4d66-9465-e19073e7c709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7289, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"Dataset-Multitask2.csv\")\n",
        "df2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "C2lfksrNIY8F",
        "outputId": "d2acd736-d2af-4c45-f477-f3a8ba1739f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4974a7114780>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset-Multitask2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset-Multitask2.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.read_csv(\"Dataset-Multitask3.csv\")\n",
        "df3.shape"
      ],
      "metadata": {
        "id": "QzQUQqe6IdzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = pd.read_csv(\"Dataset-Multitask4.csv\")\n",
        "df4.shape"
      ],
      "metadata": {
        "id": "AN-jqRpDIk6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_test = pd.read_csv(\"Dataset-Multitask1.csv\")\n",
        "# df_test.tail()"
      ],
      "metadata": {
        "id": "MnX995G-ilGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.drop(['Unnamed: 0'],axis=1)\n",
        "# df_test = df_test.drop(['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "W6Di0qLxiukF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_train = pd.concat([df_train,df_test],axis=0)"
      ],
      "metadata": {
        "id": "J6lmVDh6iwY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UC28nU4iw1c",
        "outputId": "165d844e-e0ef-4def-fadd-bb18a2351a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7289, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEXT Preprocessing"
      ],
      "metadata": {
        "id": "l8aLnsLzj3T6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Lower Casing"
      ],
      "metadata": {
        "id": "_m5y7rzBkLvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Text'] = df_train['Text'].str.lower()"
      ],
      "metadata": {
        "id": "_lUCoyGOi9se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. HTML Tags"
      ],
      "metadata": {
        "id": "zXtPt581kT2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_html_tags(text):\n",
        "  pattern = re.compile('<.*?>')\n",
        "  return pattern.sub(r'',text)"
      ],
      "metadata": {
        "id": "HctmC0vei-a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Text'] = df_train['Text'].apply(remove_html_tags)"
      ],
      "metadata": {
        "id": "xM-9s2rYi-Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing URL's in Text"
      ],
      "metadata": {
        "id": "ny5qXVGKkfVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(text):\n",
        "  pattern = re.compile(r'https?://\\S+|www\\.\\/S+')\n",
        "  return pattern.sub(r'',text)"
      ],
      "metadata": {
        "id": "97oji2iii-WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Text'] = df_train['Text'].apply(remove_url)"
      ],
      "metadata": {
        "id": "bJcAzHVoi-Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Punctuations"
      ],
      "metadata": {
        "id": "heKI9jnCklE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I7Ds76tYi-Q5",
        "outputId": "b2ddb949-7e87-463d-85cf-c3503cc49839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exclude = string.punctuation"
      ],
      "metadata": {
        "id": "snVPYX9ki-NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(text):\n",
        "  return text.translate(str.maketrans('','',exclude))"
      ],
      "metadata": {
        "id": "G4WdIvg7jjJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Text'] = df_train['Text'].apply(remove_punc)"
      ],
      "metadata": {
        "id": "SBPtzTY5jlb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Spelling Corrections"
      ],
      "metadata": {
        "id": "UKY1d81Yktih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "CgJJCWYUjmDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_spelling(text):\n",
        "  blob = TextBlob(text)\n",
        "  corrected_text = blob.correct()\n",
        "  return str(corrected_text)"
      ],
      "metadata": {
        "id": "AAQxpktpjmBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Stemming"
      ],
      "metadata": {
        "id": "Xffaint_jl-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import PorterStemmer"
      ],
      "metadata": {
        "id": "kKa69qvVk87C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "7PaTwcsHk83C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Text'] = df_train['Text'].apply(lambda x:stemmer.stem(x))"
      ],
      "metadata": {
        "id": "azjczFEllBFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Removing Stopwords"
      ],
      "metadata": {
        "id": "068i6-kJlEW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S9cUP5YlO92",
        "outputId": "54abb0b1-880a-40ac-9aac-9b876be7b968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "sw_list = stopwords.words('english')\n",
        "\n",
        "df_train['Text'].apply(lambda x:[item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAGdhKnulRE4",
        "outputId": "3ec3a3fb-51ee-45cd-f178-088e2c36f157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       peerreviewed article systematically deconstruc...\n",
              "1       dealing stress children youth living diabetes ...\n",
              "2       pandemic living stressful everyone even who’ve...\n",
              "3       stress leave tears insomnia greater victoria t...\n",
              "4       stress leave tears insomnia greater victoria t...\n",
              "                              ...                        \n",
              "7284    angellamuno lunarossa relax mate real covid19 ...\n",
              "7285        doesnt mean relax covid 19 still us wearamask\n",
              "7286    melbourne relax third lockdown new covid19 cas...\n",
              "7287    mayors vote 98 put metro manila mgcq gcq march...\n",
              "7288    return social apps news first make time availa...\n",
              "Name: Text, Length: 7289, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Tokenization"
      ],
      "metadata": {
        "id": "BkmQR4AslToH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize"
      ],
      "metadata": {
        "id": "5lLjxsC_lgmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBV6Rhzplh3i",
        "outputId": "baf6f8e4-b131-4677-f00d-921b08957c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Text'].apply(lambda x:word_tokenize(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFVhPJGwljN9",
        "outputId": "3a6ea051-f1ef-4bcf-d346-f1b57161aa0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [peerreviewed, article, that, systematically, ...\n",
              "1       [dealing, with, stress, for, children, and, yo...\n",
              "2       [pandemic, living, is, stressful, for, everyon...\n",
              "3       [stress, leave, tears, and, insomnia, greater,...\n",
              "4       [stress, leave, tears, and, insomnia, greater,...\n",
              "                              ...                        \n",
              "7284    [angellamuno, lunarossa, relax, mate, we, have...\n",
              "7285    [this, doesnt, mean, that, you, relax, on, cov...\n",
              "7286    [melbourne, to, relax, third, lockdown, as, no...\n",
              "7287    [just, in, mayors, vote, 98, to, put, metro, m...\n",
              "7288    [you, can, return, to, your, social, apps, and...\n",
              "Name: Text, Length: 7289, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Text'] = df_train['Text'].apply(lambda x:word_tokenize(x))"
      ],
      "metadata": {
        "id": "rDkNPnoGllMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df_train['Text'])"
      ],
      "metadata": {
        "id": "hwR6UekAlpTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tokenizer.texts_to_sequences(df_train['Text'])"
      ],
      "metadata": {
        "id": "iNUc9Mzmlsfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Text'].shape"
      ],
      "metadata": {
        "id": "Dlj-6UtQlt49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d0a6858-82ad-4fbb-e6bb-80a882b121b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7289,)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary based on tokenization\n",
        "vocabulary = tokenizer.word_index\n",
        "print(len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-CC0IEYlxCl",
        "outputId": "dd64c9d5-3198-412a-f89c-125a69038621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "f37QK77pl3AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3tXc7SCl3gw",
        "outputId": "2a1299d5-6d97-4d7d-b753-653faf418008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-09 10:34:07--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-10-09 10:34:07--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-10-09 10:34:08--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.09MB/s    in 2m 39s  \n",
            "\n",
            "2023-10-09 10:36:48 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcCURQxOl5Hj",
        "outputId": "e95f08e1-99e5-4ca3-8f68-77c0d9755913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ],
      "metadata": {
        "id": "VtsnbHqCl6ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_input_file = \"glove.6B.100d.txt\""
      ],
      "metadata": {
        "id": "SHx1KkJzl8R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_output_file = \"word2vec.txt\""
      ],
      "metadata": {
        "id": "tFIpYNbOl9mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove2word2vec(glove_input_file,glove_output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwTAVYoEl-8i",
        "outputId": "725b0832-b972-4afd-a3a7-415d6fc0d1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-13f14740c424>:1: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(glove_input_file,glove_output_file)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 25\n",
        "from keras.utils import pad_sequences\n",
        "lines_paded = pad_sequences(x,maxlen=25,padding='post')"
      ],
      "metadata": {
        "id": "f5IwyEz6mEa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = np.array(df_train['Sarcasm'])\n",
        "y2 = np.array(df_train['Stress'])"
      ],
      "metadata": {
        "id": "rbEi3M3AmFYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train_task1, y_val_task1, y_train_task2, y_val_task2 = train_test_split(\n",
        "    lines_paded, y1, y2, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "KWt51VHVmJDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"x_train shape {X_train.shape}\")\n",
        "print(f\"x_val shape {X_val.shape}\")\n",
        "print(f\"y_train_task1 shape {y_train_task1.shape}\")\n",
        "print(f\"y_train_task2 shape {y_train_task2.shape}\")\n",
        "print(f\"y_val_task1 shape {y_val_task1.shape}\")\n",
        "print(f\"y_val_task2 shape {y_val_task2.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mTNyCTsmL-f",
        "outputId": "748b1bb6-18f8-41d8-fe4c-a01d09004f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape (5831, 25)\n",
            "x_val shape (1458, 25)\n",
            "y_train_task1 shape (5831,)\n",
            "y_train_task2 shape (5831,)\n",
            "y_val_task1 shape (1458,)\n",
            "y_val_task2 shape (1458,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "glove_model = KeyedVectors.load_word2vec_format(glove_output_file, binary=False)\n",
        "\n",
        "vocab_size = len(vocabulary) + 1  # Add 1 for unknown words\n",
        "\n",
        "embedding_dim = 100  # Adjust the embedding dimension based on your GloVe model\n",
        "max_length = 25\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in vocabulary.items():\n",
        "    if word in glove_model:\n",
        "        embedding_matrix[i] = glove_model[word]"
      ],
      "metadata": {
        "id": "JbxkwP6ZmMxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multitask CNN architecutre"
      ],
      "metadata": {
        "id": "RywgsbUf649_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score,precision_score"
      ],
      "metadata": {
        "id": "Af7KP9Jy53yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "sequence_len= 25\n",
        "embedding_dim= 100\n",
        "input_shape = (sequence_len,)\n",
        "input_layer = Input(shape=input_shape)\n",
        "embedding_layer = Embedding(input_dim=vocab_size,\n",
        "                            output_dim=embedding_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            trainable=False)(input_layer)\n",
        "# channel 1\n",
        "dropout_1 = Dropout(0.5)(embedding_layer)\n",
        "conv_1d_1 = Conv1D(64,5,activation='relu')(dropout_1)\n",
        "dropout_2 = Dropout(0.3)(conv_1d_1)\n",
        "gmp1d_1 = GlobalMaxPool1D()(dropout_2)\n",
        "dense_control_1 = Dense(64,activation='relu')(gmp1d_1)\n",
        "\n",
        "#  Channel\n",
        "dropout_3 = Dropout(0.5)(embedding_layer)\n",
        "conv_1d_2 = Conv1D(64,5,activation='relu')(dropout_3)\n",
        "dropout_4 = Dropout(0.3)(conv_1d_2)\n",
        "gmp1d_2 = GlobalMaxPool1D()(dropout_4)\n",
        "\n",
        "# # For Task3\n",
        "# dropout_5 = Dropout(0.5)(embedding_layer)\n",
        "# conv_1d_3 = Conv1D(64,activation='relu')(dropout_5)\n",
        "# dropout_6 = Dropout(0.3)(conv_1d_3)\n",
        "# gmp1d_3 = GlobalMaxPool1D()(dropout_6)\n",
        "\n",
        "merged = Concatenate(axis=-1)([gmp1d_1,gmp1d_2])\n",
        "\n",
        "dense1 = Dense(64,activation='relu')(merged)\n",
        "output_sarcasm = Dense(1,activation='sigmoid',name='output_sarcasm')(dense1)\n",
        "output_stress = Dense(1,activation='sigmoid',name='output_stress')(dense1)\n",
        "\n",
        "model = Model(inputs=input_layer,outputs=[output_sarcasm,output_stress])\n",
        "high_learning_rate = 0.1\n",
        "model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=high_learning_rate),metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "s5h441j4BR2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e6b65b-164c-4f2e-8e79-099c8998f77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 25)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 25, 100)              508300    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 25, 100)              0         ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 25, 100)              0         ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 21, 64)               32064     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 21, 64)               32064     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 21, 64)               0         ['conv1d[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 21, 64)               0         ['conv1d_1[0][0]']            \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 64)                   0         ['dropout_1[0][0]']           \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Gl  (None, 64)                   0         ['dropout_3[0][0]']           \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 128)                  0         ['global_max_pooling1d[0][0]',\n",
            "                                                                     'global_max_pooling1d_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   8256      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " output_sarcasm (Dense)      (None, 1)                    65        ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " output_stress (Dense)       (None, 1)                    65        ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 580814 (2.22 MB)\n",
            "Trainable params: 72514 (283.26 KB)\n",
            "Non-trainable params: 508300 (1.94 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "metadata": {
        "id": "bHgzkCNTwTrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "iTA_vbUg8wp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to build a TensorBoard callback\n",
        "# def create_tensorborad_callback():\n",
        "#   # Create a log directory for storing TensorBoard logs\n",
        "#   logdir = os.path.join('/content/drive/MyDrive/logs',\n",
        "#                         # Make it so the logs get tracked whenever we run an experiment\n",
        "#                         datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "#   return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "metadata": {
        "id": "DMltZFlq-Ovk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os,datetime\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "W9Pkxm4e_XGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorboard = create_tensorborad_callback(),callbacks=[tensorboard]"
      ],
      "metadata": {
        "id": "RZfL1dxR-0z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,[y_train_task1,y_train_task2],validation_data=(X_val,[y_val_task1,y_val_task2]),epochs=15,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQg6pzGlyS0U",
        "outputId": "c3987501-1de2-4184-e5fd-8d1c3479e659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "183/183 [==============================] - 14s 13ms/step - loss: 2.1574 - output_sarcasm_loss: 0.6915 - output_stress_loss: 1.4659 - output_sarcasm_accuracy: 0.9365 - output_stress_accuracy: 0.8242 - val_loss: 0.5448 - val_output_sarcasm_loss: 0.2055 - val_output_stress_loss: 0.3394 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8649\n",
            "Epoch 2/15\n",
            "183/183 [==============================] - 1s 8ms/step - loss: 0.6048 - output_sarcasm_loss: 0.2256 - output_stress_loss: 0.3792 - output_sarcasm_accuracy: 0.9441 - output_stress_accuracy: 0.8553 - val_loss: 0.5564 - val_output_sarcasm_loss: 0.2099 - val_output_stress_loss: 0.3464 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8621\n",
            "Epoch 3/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6318 - output_sarcasm_loss: 0.2227 - output_stress_loss: 0.4091 - output_sarcasm_accuracy: 0.9443 - output_stress_accuracy: 0.8573 - val_loss: 0.5935 - val_output_sarcasm_loss: 0.2081 - val_output_stress_loss: 0.3853 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8690\n",
            "Epoch 4/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6429 - output_sarcasm_loss: 0.2129 - output_stress_loss: 0.4300 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8554 - val_loss: 0.6741 - val_output_sarcasm_loss: 0.2099 - val_output_stress_loss: 0.4642 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8532\n",
            "Epoch 5/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6722 - output_sarcasm_loss: 0.2235 - output_stress_loss: 0.4486 - output_sarcasm_accuracy: 0.9449 - output_stress_accuracy: 0.8446 - val_loss: 0.6382 - val_output_sarcasm_loss: 0.2069 - val_output_stress_loss: 0.4313 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n",
            "Epoch 6/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6534 - output_sarcasm_loss: 0.2135 - output_stress_loss: 0.4398 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8407 - val_loss: 0.6409 - val_output_sarcasm_loss: 0.2086 - val_output_stress_loss: 0.4323 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n",
            "Epoch 7/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6531 - output_sarcasm_loss: 0.2134 - output_stress_loss: 0.4397 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8407 - val_loss: 0.6411 - val_output_sarcasm_loss: 0.2078 - val_output_stress_loss: 0.4334 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n",
            "Epoch 8/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6529 - output_sarcasm_loss: 0.2129 - output_stress_loss: 0.4400 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8409 - val_loss: 0.6405 - val_output_sarcasm_loss: 0.2068 - val_output_stress_loss: 0.4337 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n",
            "Epoch 9/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6568 - output_sarcasm_loss: 0.2150 - output_stress_loss: 0.4417 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8414 - val_loss: 0.6392 - val_output_sarcasm_loss: 0.2068 - val_output_stress_loss: 0.4325 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n",
            "Epoch 10/15\n",
            "183/183 [==============================] - 2s 9ms/step - loss: 0.6533 - output_sarcasm_loss: 0.2137 - output_stress_loss: 0.4396 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8407 - val_loss: 0.6398 - val_output_sarcasm_loss: 0.2067 - val_output_stress_loss: 0.4331 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n",
            "Epoch 11/15\n",
            "183/183 [==============================] - 2s 9ms/step - loss: 0.6535 - output_sarcasm_loss: 0.2136 - output_stress_loss: 0.4398 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8407 - val_loss: 0.6380 - val_output_sarcasm_loss: 0.2067 - val_output_stress_loss: 0.4313 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n",
            "Epoch 12/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6528 - output_sarcasm_loss: 0.2131 - output_stress_loss: 0.4396 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8407 - val_loss: 0.6396 - val_output_sarcasm_loss: 0.2083 - val_output_stress_loss: 0.4313 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n",
            "Epoch 13/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6537 - output_sarcasm_loss: 0.2138 - output_stress_loss: 0.4399 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8407 - val_loss: 0.6396 - val_output_sarcasm_loss: 0.2068 - val_output_stress_loss: 0.4328 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n",
            "Epoch 14/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6546 - output_sarcasm_loss: 0.2140 - output_stress_loss: 0.4405 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8407 - val_loss: 0.6398 - val_output_sarcasm_loss: 0.2085 - val_output_stress_loss: 0.4313 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n",
            "Epoch 15/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.6537 - output_sarcasm_loss: 0.2134 - output_stress_loss: 0.4403 - output_sarcasm_accuracy: 0.9451 - output_stress_accuracy: 0.8407 - val_loss: 0.6396 - val_output_sarcasm_loss: 0.2067 - val_output_stress_loss: 0.4329 - val_output_sarcasm_accuracy: 0.9472 - val_output_stress_accuracy: 0.8450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.fit(X_train,[y_train_task1,y_train_task2],validation_data=(X_val,[y_val_task1,y_val_task2]),epochs=15,batch_size=32)"
      ],
      "metadata": {
        "id": "N9pkVqxzsi-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_task1,y_pred_task2 = model.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGZh9_yPsm7P",
        "outputId": "3209f54a-03fd-4d39-f5a7-a05e254fcee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold=0.5\n",
        "y_pred_binary1 = np.where(y_pred_task1>=threshold ,1,0)\n",
        "y_pred_binary2 = np.where(y_pred_task2>=threshold ,1,0)\n",
        "# print(y_pred_binary1)"
      ],
      "metadata": {
        "id": "RbbHdWVXssr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_Sarcasm = f1_score(y_val_task1,y_pred_binary1)\n",
        "print(f1_score_Sarcasm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ggK-fB6sy06",
        "outputId": "881fc247-7247-4844-b7c0-963f1a9148cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps_sarcasm = precision_score(y_val_task1,y_pred_binary1)\n",
        "print(ps_sarcasm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPYx_SiUBeTC",
        "outputId": "caf4cfa1-94a1-4048-946c-b306d087b1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_Stress = f1_score(y_val_task2,y_pred_binary2)\n",
        "print(f1_score_Stress )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYZhUp_GszpJ",
        "outputId": "34b9a3a7-04cc-4c33-9909-34f425ce84fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9159851301115242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps_stress = precision_score(y_val_task2,y_pred_binary2)\n",
        "print(ps_stress)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqay2RGPBxYI",
        "outputId": "8a251a60-b670-438f-e9c7-58afcb266362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8449931412894376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU CNN GRU WITH ATTENTION LAYERS"
      ],
      "metadata": {
        "id": "vtWqf-7V7AG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.layers import Concatenate\n",
        "from keras.layers import Bidirectional,GlobalMaxPool1D,Attention,RepeatVector\n",
        "from keras.optimizers import Adam\n",
        "sequence_len=25\n",
        "embedding_dim=100\n",
        "input_shape=(sequence_len,)\n",
        "input_layer = Input(shape=input_shape)\n",
        "embedding_layer = Embedding(vocab_size,embedding_dim,weights=[embedding_matrix],trainable=False)(input_layer)\n",
        "# Conv layer + Maxpool layer *3\n",
        "conv_layer=Conv1D(64,5,activation='relu')(embedding_layer)\n",
        "conv_layer = GlobalMaxPool1D()(conv_layer)\n",
        "\n",
        "# Lstm for task1\n",
        "lstm_layer1 = Bidirectional(GRU(64,return_sequences=True))(embedding_layer)\n",
        "attention_layer1 = Attention()([lstm_layer1, lstm_layer1])\n",
        "attended_lstm1 = Concatenate(axis=-1)([lstm_layer1, attention_layer1])\n",
        "lstm_layer1 = GlobalMaxPool1D()(attended_lstm1)\n",
        "\n",
        "# Lstm for task2\n",
        "lstm_layer2 = Bidirectional(GRU(64,return_sequences=True))(embedding_layer)\n",
        "attention_layer2 = Attention()([lstm_layer2, lstm_layer2])\n",
        "attended_lstm2 = Concatenate(axis=-1)([lstm_layer2, attention_layer2])\n",
        "lstm_layer2 = GlobalMaxPool1D()(attended_lstm2)\n",
        "#Reshaping\n",
        "conv_layer_reshaped = RepeatVector(sequence_len)(conv_layer)\n",
        "lstm_layer_reshaped1 = RepeatVector(sequence_len)(lstm_layer1)\n",
        "lstm_layer_reshaped2 = RepeatVector(sequence_len)(lstm_layer2)\n",
        "# concatenation\n",
        "concatenated1 = Concatenate(axis=-1)([conv_layer_reshaped,lstm_layer_reshaped1])\n",
        "concatenated2 = Concatenate(axis=-1)([conv_layer_reshaped,lstm_layer_reshaped2])\n",
        "# Flatten the concatenated output to match the shape for binary classification\n",
        "flattened_output1 = Flatten()(concatenated1)\n",
        "flattened_output2 = Flatten()(concatenated2)\n",
        "\n",
        "output1 = Dense(1,activation='sigmoid',name='sarcasm')(flattened_output1)\n",
        "output2 = Dense(1,activation='sigmoid',name='stress')(flattened_output2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=[output1,output2])\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.1), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zLRTr0J7J81",
        "outputId": "71dbeabd-1fe6-44be-9a20-efa3e7520a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 25)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 25, 100)              508300    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 25, 128)              63744     ['embedding_1[0][0]']         \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, 25, 128)              63744     ['embedding_1[0][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " attention (Attention)       (None, 25, 128)              0         ['bidirectional[0][0]',       \n",
            "                                                                     'bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " attention_1 (Attention)     (None, 25, 128)              0         ['bidirectional_1[0][0]',     \n",
            "                                                                     'bidirectional_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 21, 64)               32064     ['embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 25, 256)              0         ['bidirectional[0][0]',       \n",
            " )                                                                   'attention[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 25, 256)              0         ['bidirectional_1[0][0]',     \n",
            " )                                                                   'attention_1[0][0]']         \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Gl  (None, 64)                   0         ['conv1d_2[0][0]']            \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_3 (Gl  (None, 256)                  0         ['concatenate_1[0][0]']       \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_4 (Gl  (None, 256)                  0         ['concatenate_2[0][0]']       \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVecto  (None, 25, 64)               0         ['global_max_pooling1d_2[0][0]\n",
            " r)                                                                 ']                            \n",
            "                                                                                                  \n",
            " repeat_vector_1 (RepeatVec  (None, 25, 256)              0         ['global_max_pooling1d_3[0][0]\n",
            " tor)                                                               ']                            \n",
            "                                                                                                  \n",
            " repeat_vector_2 (RepeatVec  (None, 25, 256)              0         ['global_max_pooling1d_4[0][0]\n",
            " tor)                                                               ']                            \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 25, 320)              0         ['repeat_vector[0][0]',       \n",
            " )                                                                   'repeat_vector_1[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 25, 320)              0         ['repeat_vector[0][0]',       \n",
            " )                                                                   'repeat_vector_2[0][0]']     \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 8000)                 0         ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 8000)                 0         ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " sarcasm (Dense)             (None, 1)                    8001      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " stress (Dense)              (None, 1)                    8001      ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 683854 (2.61 MB)\n",
            "Trainable params: 175554 (685.76 KB)\n",
            "Non-trainable params: 508300 (1.94 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,[y_train_task1,y_train_task2],validation_data=(X_val,[y_val_task1,y_val_task2]),epochs=15,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0zMI8jPpsfe",
        "outputId": "7a213438-5954-4670-de17-6757127fe838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "183/183 [==============================] - 17s 37ms/step - loss: 26.3246 - sarcasm_loss: 14.8189 - stress_loss: 11.5057 - sarcasm_accuracy: 0.8928 - stress_accuracy: 0.8429 - val_loss: 25.8982 - val_sarcasm_loss: 17.8886 - val_stress_loss: 8.0095 - val_sarcasm_accuracy: 0.9396 - val_stress_accuracy: 0.7826\n",
            "Epoch 2/15\n",
            "183/183 [==============================] - 7s 40ms/step - loss: 22.4928 - sarcasm_loss: 15.6928 - stress_loss: 6.8000 - sarcasm_accuracy: 0.9010 - stress_accuracy: 0.8966 - val_loss: 24.4217 - val_sarcasm_loss: 19.7823 - val_stress_loss: 4.6394 - val_sarcasm_accuracy: 0.9444 - val_stress_accuracy: 0.9390\n",
            "Epoch 3/15\n",
            "183/183 [==============================] - 5s 28ms/step - loss: 20.3313 - sarcasm_loss: 15.1281 - stress_loss: 5.2032 - sarcasm_accuracy: 0.9034 - stress_accuracy: 0.9189 - val_loss: 16.8994 - val_sarcasm_loss: 9.8216 - val_stress_loss: 7.0777 - val_sarcasm_accuracy: 0.8992 - val_stress_accuracy: 0.8882\n",
            "Epoch 4/15\n",
            "183/183 [==============================] - 5s 25ms/step - loss: 30.5265 - sarcasm_loss: 23.0336 - stress_loss: 7.4930 - sarcasm_accuracy: 0.9046 - stress_accuracy: 0.9172 - val_loss: 27.1976 - val_sarcasm_loss: 11.5655 - val_stress_loss: 15.6321 - val_sarcasm_accuracy: 0.9410 - val_stress_accuracy: 0.9136\n",
            "Epoch 5/15\n",
            "183/183 [==============================] - 3s 17ms/step - loss: 25.2253 - sarcasm_loss: 15.7026 - stress_loss: 9.5228 - sarcasm_accuracy: 0.8998 - stress_accuracy: 0.8966 - val_loss: 40.4326 - val_sarcasm_loss: 23.8022 - val_stress_loss: 16.6304 - val_sarcasm_accuracy: 0.9198 - val_stress_accuracy: 0.9095\n",
            "Epoch 6/15\n",
            "183/183 [==============================] - 4s 23ms/step - loss: 22.9378 - sarcasm_loss: 13.3206 - stress_loss: 9.6172 - sarcasm_accuracy: 0.9057 - stress_accuracy: 0.9103 - val_loss: 19.0932 - val_sarcasm_loss: 12.1120 - val_stress_loss: 6.9811 - val_sarcasm_accuracy: 0.9465 - val_stress_accuracy: 0.9438\n",
            "Epoch 7/15\n",
            "183/183 [==============================] - 5s 27ms/step - loss: 13.3547 - sarcasm_loss: 9.0415 - stress_loss: 4.3132 - sarcasm_accuracy: 0.9067 - stress_accuracy: 0.9389 - val_loss: 13.0392 - val_sarcasm_loss: 7.1349 - val_stress_loss: 5.9042 - val_sarcasm_accuracy: 0.9458 - val_stress_accuracy: 0.9314\n",
            "Epoch 8/15\n",
            "183/183 [==============================] - 5s 28ms/step - loss: 15.8991 - sarcasm_loss: 10.9317 - stress_loss: 4.9673 - sarcasm_accuracy: 0.9017 - stress_accuracy: 0.9393 - val_loss: 8.3753 - val_sarcasm_loss: 3.7662 - val_stress_loss: 4.6091 - val_sarcasm_accuracy: 0.9438 - val_stress_accuracy: 0.9595\n",
            "Epoch 9/15\n",
            "183/183 [==============================] - 8s 46ms/step - loss: 13.8715 - sarcasm_loss: 8.7589 - stress_loss: 5.1127 - sarcasm_accuracy: 0.9067 - stress_accuracy: 0.9304 - val_loss: 20.5497 - val_sarcasm_loss: 13.4753 - val_stress_loss: 7.0744 - val_sarcasm_accuracy: 0.5734 - val_stress_accuracy: 0.9479\n",
            "Epoch 10/15\n",
            "183/183 [==============================] - 7s 38ms/step - loss: 15.3037 - sarcasm_loss: 12.1045 - stress_loss: 3.1992 - sarcasm_accuracy: 0.9043 - stress_accuracy: 0.9417 - val_loss: 11.0704 - val_sarcasm_loss: 6.3877 - val_stress_loss: 4.6828 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.9486\n",
            "Epoch 11/15\n",
            "183/183 [==============================] - 4s 24ms/step - loss: 13.2151 - sarcasm_loss: 9.2414 - stress_loss: 3.9737 - sarcasm_accuracy: 0.9060 - stress_accuracy: 0.9297 - val_loss: 10.0068 - val_sarcasm_loss: 5.5622 - val_stress_loss: 4.4446 - val_sarcasm_accuracy: 0.9444 - val_stress_accuracy: 0.9499\n",
            "Epoch 12/15\n",
            "183/183 [==============================] - 3s 14ms/step - loss: 13.3326 - sarcasm_loss: 9.9206 - stress_loss: 3.4120 - sarcasm_accuracy: 0.9057 - stress_accuracy: 0.9475 - val_loss: 14.3758 - val_sarcasm_loss: 3.8587 - val_stress_loss: 10.5172 - val_sarcasm_accuracy: 0.9438 - val_stress_accuracy: 0.8299\n",
            "Epoch 13/15\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 10.0046 - sarcasm_loss: 6.7329 - stress_loss: 3.2718 - sarcasm_accuracy: 0.9065 - stress_accuracy: 0.9436 - val_loss: 10.8392 - val_sarcasm_loss: 5.8728 - val_stress_loss: 4.9663 - val_sarcasm_accuracy: 0.7140 - val_stress_accuracy: 0.9403\n",
            "Epoch 14/15\n",
            "183/183 [==============================] - 3s 15ms/step - loss: 9.1977 - sarcasm_loss: 6.7034 - stress_loss: 2.4942 - sarcasm_accuracy: 0.9055 - stress_accuracy: 0.9510 - val_loss: 11.3548 - val_sarcasm_loss: 3.2892 - val_stress_loss: 8.0656 - val_sarcasm_accuracy: 0.9390 - val_stress_accuracy: 0.9143\n",
            "Epoch 15/15\n",
            "183/183 [==============================] - 3s 15ms/step - loss: 10.4706 - sarcasm_loss: 7.3210 - stress_loss: 3.1495 - sarcasm_accuracy: 0.9089 - stress_accuracy: 0.9513 - val_loss: 10.4403 - val_sarcasm_loss: 6.1336 - val_stress_loss: 4.3067 - val_sarcasm_accuracy: 0.9458 - val_stress_accuracy: 0.9342\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dfa0c752d40>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_task1,y_pred_task2 = model.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPAGvxDlpz4w",
        "outputId": "f64ab4c6-69c3-48cb-d775-1aec0973af8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold=0.5\n",
        "y_pred_binary1 = np.where(y_pred_task1>=threshold ,1,0)\n",
        "y_pred_binary2 = np.where(y_pred_task2>=threshold ,1,0)\n",
        "print(y_pred_binary1)"
      ],
      "metadata": {
        "id": "0iMG4Krqp1XH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ba5cd2-6bdd-4be7-bd7e-a496472d399f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_Sarcasm = f1_score(y_val_task1,y_pred_binary1)\n",
        "print(f1_score_Sarcasm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTPv_AH1p9D_",
        "outputId": "248b7376-7c00-4070-9800-86edda419f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07058823529411765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps_sarcasm = precision_score(y_val_task1,y_pred_binary1)\n",
        "print(ps_sarcasm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw8kJXc5CGna",
        "outputId": "ac540b6e-a455-4e37-8bb6-2da52624f8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_Stress = f1_score(y_val_task2,y_pred_binary2)\n",
        "print(f1_score_Stress )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBuYlFcdqOtl",
        "outputId": "c840a080-43d3-4845-ebcb-56512d38dcc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9600000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps_stress = precision_score(y_val_task2,y_pred_binary2)\n",
        "print(ps_stress)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaLCnm3-CRo_",
        "outputId": "22c19e53-d0c0-4199-9787-a61ed9c89c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9863013698630136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "sequence_len=25\n",
        "embedding_dim=100\n",
        "input_shape=(sequence_len,)\n",
        "input_layer = Input(shape=input_shape)\n",
        "embedding_layer = Embedding(vocab_size,embedding_dim,weights=[embedding_matrix],trainable=False)(input_layer)\n",
        "\n",
        "BiGRU_layer = Bidirectional(GRU(64,return_sequences=True))(embedding_layer)\n",
        "attention_layer = Attention()([BiGRU_layer,BiGRU_layer])\n",
        "concatenated_layer = Concatenate(axis=-1)([attention_layer,BiGRU_layer])\n",
        "gmp_layer = GlobalMaxPool1D()(concatenated_layer)\n",
        "\n",
        "dense_layer1 = Dense(64,activation='relu')(gmp_layer)\n",
        "dense_layer2 = Dense(64,activation='relu')(gmp_layer)\n",
        "\n",
        "output_sarcasm = Dense(1,activation='sigmoid',name='sarcasm')(dense_layer1)\n",
        "concatenated_for_stress = Concatenate(axis=-1)([dense_layer2,output_sarcasm])\n",
        "output_stress = Dense(1,activation='sigmoid',name='stress')(concatenated_for_stress)\n",
        "\n",
        "model = Model(inputs=input_layer,outputs=[output_sarcasm,output_stress])\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.1), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs8MTb_3AVME",
        "outputId": "ed75201c-c564-43a7-cb46-5e060c0d3079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 25)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, 25, 100)              508300    ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirecti  (None, 25, 128)              63744     ['embedding_2[0][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " attention_2 (Attention)     (None, 25, 128)              0         ['bidirectional_2[0][0]',     \n",
            "                                                                     'bidirectional_2[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 25, 256)              0         ['attention_2[0][0]',         \n",
            " )                                                                   'bidirectional_2[0][0]']     \n",
            "                                                                                                  \n",
            " global_max_pooling1d_5 (Gl  (None, 256)                  0         ['concatenate_5[0][0]']       \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 64)                   16448     ['global_max_pooling1d_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " sarcasm (Dense)             (None, 1)                    65        ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 64)                   16448     ['global_max_pooling1d_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 65)                   0         ['dense_3[0][0]',             \n",
            " )                                                                   'sarcasm[0][0]']             \n",
            "                                                                                                  \n",
            " stress (Dense)              (None, 1)                    66        ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 605071 (2.31 MB)\n",
            "Trainable params: 96771 (378.01 KB)\n",
            "Non-trainable params: 508300 (1.94 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,[y_train_task1,y_train_task2],validation_data=(X_val,[y_val_task1,y_val_task2]),epochs=15,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0uVbs9c8Wbw",
        "outputId": "b8ecd694-0e13-460f-fcaa-213eaea0f48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "183/183 [==============================] - 8s 17ms/step - loss: 0.8799 - sarcasm_loss: 0.3234 - stress_loss: 0.5565 - sarcasm_accuracy: 0.9386 - stress_accuracy: 0.8343 - val_loss: 0.6349 - val_sarcasm_loss: 0.2064 - val_stress_loss: 0.4285 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 2/15\n",
            "183/183 [==============================] - 2s 13ms/step - loss: 0.6509 - sarcasm_loss: 0.2121 - stress_loss: 0.4388 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6391 - val_sarcasm_loss: 0.2066 - val_stress_loss: 0.4325 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 3/15\n",
            "183/183 [==============================] - 2s 11ms/step - loss: 0.6527 - sarcasm_loss: 0.2144 - stress_loss: 0.4383 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.7013 - val_sarcasm_loss: 0.2124 - val_stress_loss: 0.4889 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 4/15\n",
            "183/183 [==============================] - 2s 13ms/step - loss: 0.6690 - sarcasm_loss: 0.2215 - stress_loss: 0.4475 - sarcasm_accuracy: 0.9446 - stress_accuracy: 0.8407 - val_loss: 0.6448 - val_sarcasm_loss: 0.2068 - val_stress_loss: 0.4380 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 5/15\n",
            "183/183 [==============================] - 3s 18ms/step - loss: 0.6532 - sarcasm_loss: 0.2137 - stress_loss: 0.4395 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6385 - val_sarcasm_loss: 0.2067 - val_stress_loss: 0.4318 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 6/15\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.6529 - sarcasm_loss: 0.2130 - stress_loss: 0.4400 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6414 - val_sarcasm_loss: 0.2069 - val_stress_loss: 0.4345 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 7/15\n",
            "183/183 [==============================] - 4s 19ms/step - loss: 0.6536 - sarcasm_loss: 0.2141 - stress_loss: 0.4395 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6431 - val_sarcasm_loss: 0.2083 - val_stress_loss: 0.4349 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 8/15\n",
            "183/183 [==============================] - 3s 18ms/step - loss: 0.6531 - sarcasm_loss: 0.2133 - stress_loss: 0.4398 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6415 - val_sarcasm_loss: 0.2068 - val_stress_loss: 0.4347 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 9/15\n",
            "183/183 [==============================] - 3s 16ms/step - loss: 0.6535 - sarcasm_loss: 0.2137 - stress_loss: 0.4398 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6415 - val_sarcasm_loss: 0.2085 - val_stress_loss: 0.4329 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 10/15\n",
            "183/183 [==============================] - 3s 15ms/step - loss: 0.6536 - sarcasm_loss: 0.2137 - stress_loss: 0.4399 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6403 - val_sarcasm_loss: 0.2067 - val_stress_loss: 0.4336 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 11/15\n",
            "183/183 [==============================] - 2s 11ms/step - loss: 0.6536 - sarcasm_loss: 0.2136 - stress_loss: 0.4399 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6394 - val_sarcasm_loss: 0.2072 - val_stress_loss: 0.4322 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 12/15\n",
            "183/183 [==============================] - 2s 10ms/step - loss: 0.6537 - sarcasm_loss: 0.2138 - stress_loss: 0.4399 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6381 - val_sarcasm_loss: 0.2068 - val_stress_loss: 0.4313 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 13/15\n",
            "183/183 [==============================] - 2s 11ms/step - loss: 0.6543 - sarcasm_loss: 0.2142 - stress_loss: 0.4401 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6388 - val_sarcasm_loss: 0.2067 - val_stress_loss: 0.4321 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 14/15\n",
            "183/183 [==============================] - 2s 11ms/step - loss: 0.6536 - sarcasm_loss: 0.2137 - stress_loss: 0.4400 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6397 - val_sarcasm_loss: 0.2080 - val_stress_loss: 0.4317 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n",
            "Epoch 15/15\n",
            "183/183 [==============================] - 2s 11ms/step - loss: 0.6524 - sarcasm_loss: 0.2131 - stress_loss: 0.4393 - sarcasm_accuracy: 0.9451 - stress_accuracy: 0.8407 - val_loss: 0.6402 - val_sarcasm_loss: 0.2088 - val_stress_loss: 0.4313 - val_sarcasm_accuracy: 0.9472 - val_stress_accuracy: 0.8450\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7df9a0faf040>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_task1,y_pred_task2 = model.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfB4FBLw5bWd",
        "outputId": "5ddc215c-e4d9-4388-ccde-35b9bec40130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 1s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred_task1.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGgbcYYH5wtR",
        "outputId": "32c8ec74-375c-4077-d0df-3970b929de8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15533917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold=0.5\n",
        "y_pred_binary1 = np.where(y_pred_task1>=threshold ,1,0)\n",
        "y_pred_binary2 = np.where(y_pred_task2>=threshold ,1,0)\n",
        "print(y_pred_binary1)"
      ],
      "metadata": {
        "id": "wHjZw5y95kS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc50049-c13b-468b-afd5-37454748975f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_task1[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I6tBcn-5-7R",
        "outputId": "b3274d74-063d-4bb0-92e9-f8fc0335dda8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_binary1[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46HVwhhX6Pi6",
        "outputId": "c251ca6d-8623-4b7f-af56-a9b46465d63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_Sarcasm = f1_score(y_val_task1,y_pred_binary1)\n",
        "print(f1_score_Sarcasm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d4jV65U5tnX",
        "outputId": "60e4f41e-d1c8-4cd6-a73f-5f1eb3b102de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps_sarcasm = precision_score(y_val_task1,y_pred_binary1)\n",
        "print(ps_sarcasm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejPZDhj8CgSL",
        "outputId": "61343c3b-6c3e-45e7-c5e4-63e2dba1f84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_Stress = f1_score(y_val_task2,y_pred_binary2)\n",
        "print(f1_score_Stress )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz3c9UW458HN",
        "outputId": "d4be5789-f073-4ca0-cc23-c8013e5fab44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9159851301115242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps_stress = precision_score(y_val_task2,y_pred_binary2)\n",
        "print(ps_stress)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBGlazZ_Ci7D",
        "outputId": "d2efd3a7-32e7-4e10-a22b-fbf5bb519c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8449931412894376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MZox-gUOspDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !tensorboard dev upload \\\n",
        "# --logdir \"/content/drive/MyDrive/logs\" \\\n",
        "# --name \"Sarcasm and Stress Multichannel CNN with 4 datasets\" \\\n",
        "# --one_shot"
      ],
      "metadata": {
        "id": "876HGTYLCY4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.layers import Bidirectional\n",
        "inp = Input(shape=(25,))\n",
        "x = Embedding(vocab_size, 100, weights=[embedding_matrix],trainable=False)(inp)\n",
        "x = LSTM(1, return_sequences=True)(x)#return_sequences=True\n",
        "x = GlobalMaxPool1D()(x)\n",
        "# x = Dense(50, activation=\"relu\")(x)\n",
        "# x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.1), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9AAJuCImFIw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train_task1,validation_data=(X_val,y_val_task1),epochs=15,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL8eJbMXBkYH",
        "outputId": "def01e88-4279-43af-95b2-d32739b0557c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "183/183 [==============================] - 7s 13ms/step - loss: 0.2202 - accuracy: 0.9451 - val_loss: 0.2067 - val_accuracy: 0.9472\n",
            "Epoch 2/15\n",
            "183/183 [==============================] - 2s 11ms/step - loss: 0.2148 - accuracy: 0.9451 - val_loss: 0.2072 - val_accuracy: 0.9472\n",
            "Epoch 3/15\n",
            "183/183 [==============================] - 2s 10ms/step - loss: 0.2143 - accuracy: 0.9451 - val_loss: 0.2068 - val_accuracy: 0.9472\n",
            "Epoch 4/15\n",
            "183/183 [==============================] - 2s 9ms/step - loss: 0.2152 - accuracy: 0.9451 - val_loss: 0.2073 - val_accuracy: 0.9472\n",
            "Epoch 5/15\n",
            "183/183 [==============================] - 2s 11ms/step - loss: 0.2157 - accuracy: 0.9451 - val_loss: 0.2086 - val_accuracy: 0.9472\n",
            "Epoch 6/15\n",
            "183/183 [==============================] - 2s 10ms/step - loss: 0.2146 - accuracy: 0.9451 - val_loss: 0.2069 - val_accuracy: 0.9472\n",
            "Epoch 7/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.2148 - accuracy: 0.9451 - val_loss: 0.2071 - val_accuracy: 0.9472\n",
            "Epoch 8/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.2155 - accuracy: 0.9451 - val_loss: 0.2087 - val_accuracy: 0.9472\n",
            "Epoch 9/15\n",
            "183/183 [==============================] - 2s 12ms/step - loss: 0.2146 - accuracy: 0.9451 - val_loss: 0.2068 - val_accuracy: 0.9472\n",
            "Epoch 10/15\n",
            "183/183 [==============================] - 2s 12ms/step - loss: 0.2140 - accuracy: 0.9451 - val_loss: 0.2069 - val_accuracy: 0.9472\n",
            "Epoch 11/15\n",
            "183/183 [==============================] - 2s 9ms/step - loss: 0.2147 - accuracy: 0.9451 - val_loss: 0.2067 - val_accuracy: 0.9472\n",
            "Epoch 12/15\n",
            "183/183 [==============================] - 1s 8ms/step - loss: 0.2150 - accuracy: 0.9451 - val_loss: 0.2076 - val_accuracy: 0.9472\n",
            "Epoch 13/15\n",
            "183/183 [==============================] - 1s 6ms/step - loss: 0.2149 - accuracy: 0.9451 - val_loss: 0.2081 - val_accuracy: 0.9472\n",
            "Epoch 14/15\n",
            "183/183 [==============================] - 1s 6ms/step - loss: 0.2151 - accuracy: 0.9451 - val_loss: 0.2091 - val_accuracy: 0.9472\n",
            "Epoch 15/15\n",
            "183/183 [==============================] - 1s 6ms/step - loss: 0.2145 - accuracy: 0.9451 - val_loss: 0.2098 - val_accuracy: 0.9472\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7df999991780>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_task1 = model.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxW3mbVFBlJZ",
        "outputId": "c6d26f78-c050-483e-85e8-28abdc841c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "threshold = 0.5  # Adjust this threshold as needed\n",
        "y_pred_binary = np.where(y_pred_task1 >= threshold, 1, 0)\n",
        "print(y_pred_binary[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhQsWnfVBolp",
        "outputId": "85f7372b-5981-48cf-b36e-4a1bfbc0310f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_Sarcasm = f1_score(y_val_task1,y_pred_binary)\n",
        "print(f1_score_Sarcasm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2y_Qwm3BoiX",
        "outputId": "ef738edf-ac8f-410b-d902-a975cf325889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10084033613445378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps_sarcasm = precision_score(y_val_task1,y_pred_binary1)\n",
        "print(ps_sarcasm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_bW2nGnDE3d",
        "outputId": "1acbf61f-bb22-42d1-edad-e25b0a39a233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train_task2,validation_data=(X_val,y_val_task2),epochs=15,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjl9t_v5BwIC",
        "outputId": "b6830d04-4159-4578-ee25-db435f4a90f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.5161 - accuracy: 0.8180 - val_loss: 0.4368 - val_accuracy: 0.8450\n",
            "Epoch 2/15\n",
            "183/183 [==============================] - 2s 9ms/step - loss: 0.4399 - accuracy: 0.8407 - val_loss: 0.4465 - val_accuracy: 0.8450\n",
            "Epoch 3/15\n",
            "183/183 [==============================] - 1s 8ms/step - loss: 0.4421 - accuracy: 0.8407 - val_loss: 0.4314 - val_accuracy: 0.8450\n",
            "Epoch 4/15\n",
            "183/183 [==============================] - 1s 6ms/step - loss: 0.4417 - accuracy: 0.8407 - val_loss: 0.4314 - val_accuracy: 0.8450\n",
            "Epoch 5/15\n",
            "183/183 [==============================] - 1s 6ms/step - loss: 0.4409 - accuracy: 0.8407 - val_loss: 0.4319 - val_accuracy: 0.8450\n",
            "Epoch 6/15\n",
            "183/183 [==============================] - 1s 8ms/step - loss: 0.4402 - accuracy: 0.8407 - val_loss: 0.4348 - val_accuracy: 0.8450\n",
            "Epoch 7/15\n",
            "183/183 [==============================] - 2s 9ms/step - loss: 0.4407 - accuracy: 0.8407 - val_loss: 0.4315 - val_accuracy: 0.8450\n",
            "Epoch 8/15\n",
            "183/183 [==============================] - 2s 9ms/step - loss: 0.4415 - accuracy: 0.8407 - val_loss: 0.4343 - val_accuracy: 0.8450\n",
            "Epoch 9/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.4411 - accuracy: 0.8407 - val_loss: 0.4439 - val_accuracy: 0.8450\n",
            "Epoch 10/15\n",
            "183/183 [==============================] - 1s 6ms/step - loss: 0.4423 - accuracy: 0.8407 - val_loss: 0.4434 - val_accuracy: 0.8450\n",
            "Epoch 11/15\n",
            "183/183 [==============================] - 2s 9ms/step - loss: 0.4416 - accuracy: 0.8407 - val_loss: 0.4337 - val_accuracy: 0.8450\n",
            "Epoch 12/15\n",
            "183/183 [==============================] - 1s 7ms/step - loss: 0.4430 - accuracy: 0.8407 - val_loss: 0.4334 - val_accuracy: 0.8450\n",
            "Epoch 13/15\n",
            "183/183 [==============================] - 1s 6ms/step - loss: 0.4408 - accuracy: 0.8407 - val_loss: 0.4321 - val_accuracy: 0.8450\n",
            "Epoch 14/15\n",
            "183/183 [==============================] - 1s 6ms/step - loss: 0.4409 - accuracy: 0.8407 - val_loss: 0.4408 - val_accuracy: 0.8450\n",
            "Epoch 15/15\n",
            "183/183 [==============================] - 1s 6ms/step - loss: 0.4398 - accuracy: 0.8407 - val_loss: 0.4313 - val_accuracy: 0.8450\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7df9999b6800>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_task2 = model.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXgCUjAkB4mP",
        "outputId": "ac65a375-60bc-4f97-ce96-cf3a2b911d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_binary2 = np.where(y_pred_task2 >= threshold, 1, 0)\n",
        "print(y_pred_binary2[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF_I4VVkB6yP",
        "outputId": "096b8380-10ef-4c18-b6c5-485b5b6359cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_Stress = f1_score(y_val_task2,y_pred_binary2)\n",
        "print(f1_score_Stress)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaAkUJmOCBV9",
        "outputId": "1c50912b-2593-43a5-fdeb-0aa2cb258621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9159851301115242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps_stress = precision_score(y_val_task2,y_pred_binary2)\n",
        "print(ps_stress)"
      ],
      "metadata": {
        "id": "rjfDotlCCHjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e793f6-c828-4b21-f702-358ea122d378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8449931412894376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c2vacceVDJ5_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}